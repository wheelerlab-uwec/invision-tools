{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import trackpy as tp\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import gzip\n",
    "import pickle\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/groups/wheelenj/mosquitoes/20250106a01ard_20250106_111656.24568744/000001.hdf5',\n",
       " '/data/groups/wheelenj/mosquitoes/20250106a01ard_20250106_111656.24568744/000000.hdf5']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = '/data/groups/wheelenj/mosquitoes/20250106a01ard_20250106_111656.24568744'\n",
    "    \n",
    "hdf5_files = glob.glob(f\"{input}/*.hdf5\")\n",
    "hdf5_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data from 000000\n",
      "5457 frames in 000000\n",
      "Getting data from 000001\n",
      "Skipping empty file: 000001\n",
      "2946 rows in merged data frame.\n",
      "Writing pickle file.\n"
     ]
    }
   ],
   "source": [
    "merged = merge_data(sorted(hdf5_files), input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 80: 21 trajectories present.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tracks \u001b[39m=\u001b[39m generate_tracks(merged, \u001b[39minput\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m, in \u001b[0;36mgenerate_tracks\u001b[0;34m(df, input)\u001b[0m\n\u001b[1;32m     14\u001b[0m     adaptive_stop \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLinking particles.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m t \u001b[39m=\u001b[39m tp\u001b[39m.\u001b[39;49mlink(df, search_range\u001b[39m=\u001b[39;49msearch_range,\n\u001b[1;32m     18\u001b[0m             memory\u001b[39m=\u001b[39;49mmemory, adaptive_stop\u001b[39m=\u001b[39;49madaptive_stop)\n\u001b[1;32m     19\u001b[0m pickle_path \u001b[39m=\u001b[39m Path(\u001b[39minput\u001b[39m, Path(\u001b[39minput\u001b[39m)\u001b[39m.\u001b[39mstem \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_tracks.pkl.gz\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[39mwith\u001b[39;00m gzip\u001b[39m.\u001b[39mopen(pickle_path, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/.conda/envs/invision-env/lib/python3.11/site-packages/trackpy/linking/linking.py:192\u001b[0m, in \u001b[0;36mlink\u001b[0;34m(f, search_range, pos_columns, t_column, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m coords_iter \u001b[39m=\u001b[39m coords_from_df(f, pos_columns, t_column)\n\u001b[1;32m    191\u001b[0m ids \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 192\u001b[0m \u001b[39mfor\u001b[39;49;00m i, _ids \u001b[39min\u001b[39;49;00m link_iter(coords_iter, search_range, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs):\n\u001b[1;32m    193\u001b[0m     ids\u001b[39m.\u001b[39;49mextend(_ids)\n\u001b[1;32m    195\u001b[0m f[\u001b[39m'\u001b[39m\u001b[39mparticle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m ids\n",
      "File \u001b[0;32m~/.conda/envs/invision-env/lib/python3.11/site-packages/trackpy/linking/linking.py:102\u001b[0m, in \u001b[0;36mlink_iter\u001b[0;34m(coords_iter, search_range, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39myield\u001b[39;00m t, linker\u001b[39m.\u001b[39mparticle_ids\n\u001b[1;32m    101\u001b[0m \u001b[39mfor\u001b[39;00m t, coords \u001b[39min\u001b[39;00m coords_iter:\n\u001b[0;32m--> 102\u001b[0m     linker\u001b[39m.\u001b[39;49mnext_level(coords, t)\n\u001b[1;32m    103\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mFrame \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m trajectories present.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(t, \u001b[39mlen\u001b[39m(linker\u001b[39m.\u001b[39mparticle_ids)))\n\u001b[1;32m    104\u001b[0m     \u001b[39myield\u001b[39;00m t, linker\u001b[39m.\u001b[39mparticle_ids\n",
      "File \u001b[0;32m~/.conda/envs/invision-env/lib/python3.11/site-packages/trackpy/linking/linking.py:511\u001b[0m, in \u001b[0;36mLinker.next_level\u001b[0;34m(self, coords, t, extra_data)\u001b[0m\n\u001b[1;32m    507\u001b[0m prev_hash \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_hash(coords, t, extra_data)\n\u001b[1;32m    509\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubnets \u001b[39m=\u001b[39m Subnets(prev_hash, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhash, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_range,\n\u001b[1;32m    510\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMAX_NEIGHBORS)\n\u001b[0;32m--> 511\u001b[0m spl, dpl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massign_links()\n\u001b[1;32m    512\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_links(spl, dpl)\n",
      "File \u001b[0;32m~/.conda/envs/invision-env/lib/python3.11/site-packages/trackpy/linking/linking.py:520\u001b[0m, in \u001b[0;36mLinker.assign_links\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[39mfor\u001b[39;00m sp \u001b[39min\u001b[39;00m source_set:\n\u001b[1;32m    518\u001b[0m     sp\u001b[39m.\u001b[39mforward_cands\u001b[39m.\u001b[39msort(key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m1\u001b[39m])\n\u001b[0;32m--> 520\u001b[0m sn_spl, sn_dpl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubnet_linker(source_set, dest_set,\n\u001b[1;32m    521\u001b[0m                                     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msearch_range)\n\u001b[1;32m    522\u001b[0m spl\u001b[39m.\u001b[39mextend(sn_spl)\n\u001b[1;32m    523\u001b[0m dpl\u001b[39m.\u001b[39mextend(sn_dpl)\n",
      "File \u001b[0;32m~/.conda/envs/invision-env/lib/python3.11/site-packages/trackpy/linking/subnetlinker.py:390\u001b[0m, in \u001b[0;36msubnet_linker_recursive\u001b[0;34m(source_set, dest_set, search_range, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mfor\u001b[39;00m _s \u001b[39min\u001b[39;00m source_set:\n\u001b[1;32m    388\u001b[0m     _s\u001b[39m.\u001b[39mforward_cands\u001b[39m.\u001b[39mappend((\u001b[39mNone\u001b[39;00m, search_range))\n\u001b[0;32m--> 390\u001b[0m snl \u001b[39m=\u001b[39m SubnetLinker(source_set, \u001b[39mlen\u001b[39;49m(dest_set), search_range, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    391\u001b[0m sn_spl, sn_dpl \u001b[39m=\u001b[39m [\u001b[39mlist\u001b[39m(particles) \u001b[39mfor\u001b[39;00m particles \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39msnl\u001b[39m.\u001b[39mbest_pairs)]\n\u001b[1;32m    393\u001b[0m \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m dest_set \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(sn_dpl):\n\u001b[1;32m    394\u001b[0m     \u001b[39m# Unclaimed destination particle in subnet\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/invision-env/lib/python3.11/site-packages/trackpy/linking/subnetlinker.py:44\u001b[0m, in \u001b[0;36mSubnetLinker.__init__\u001b[0;34m(self, s_sn, dest_size, search_range, max_size)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mraise\u001b[39;00m SubnetOversizeException(\u001b[39m\"\u001b[39m\u001b[39mSubnetwork contains \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m points\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m                                   \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMAX)\n\u001b[1;32m     43\u001b[0m \u001b[39m# do the computation\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_recur(\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m~/.conda/envs/invision-env/lib/python3.11/site-packages/trackpy/linking/subnetlinker.py:77\u001b[0m, in \u001b[0;36mSubnetLinker.do_recur\u001b[0;34m(self, j)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_pairs)\n\u001b[1;32m     75\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     \u001b[39m# re curse!\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_recur(j \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     78\u001b[0m \u001b[39m# remove this step from the working\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_sum \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m dist\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/invision-env/lib/python3.11/site-packages/trackpy/linking/subnetlinker.py:77\u001b[0m, in \u001b[0;36mSubnetLinker.do_recur\u001b[0;34m(self, j)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_pairs)\n\u001b[1;32m     75\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     \u001b[39m# re curse!\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_recur(j \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     78\u001b[0m \u001b[39m# remove this step from the working\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_sum \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m dist\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n",
      "    \u001b[0;31m[... skipping similar frames: SubnetLinker.do_recur at line 77 (11 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/invision-env/lib/python3.11/site-packages/trackpy/linking/subnetlinker.py:77\u001b[0m, in \u001b[0;36mSubnetLinker.do_recur\u001b[0;34m(self, j)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_pairs)\n\u001b[1;32m     75\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     \u001b[39m# re curse!\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_recur(j \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     78\u001b[0m \u001b[39m# remove this step from the working\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_sum \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m dist\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/invision-env/lib/python3.11/site-packages/trackpy/linking/subnetlinker.py:82\u001b[0m, in \u001b[0;36mSubnetLinker.do_recur\u001b[0;34m(self, j)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[39mif\u001b[39;00m cur_d \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_taken\u001b[39m.\u001b[39mremove(cur_d)\n\u001b[0;32m---> 82\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_pairs\u001b[39m.\u001b[39mpop()\n\u001b[1;32m     83\u001b[0m \u001b[39mpass\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tracks = generate_tracks(merged, input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_tracks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_tracks(tracks, args\u001b[39m.\u001b[39minput)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_tracks' is not defined"
     ]
    }
   ],
   "source": [
    "plot_tracks(tracks, args.input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(hdf5s, input):\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    i = 0\n",
    "    for file, i in zip(hdf5s, range(len(hdf5s))):\n",
    "        with tp.PandasHDFStore(file, mode=\"r\") as hdf5:\n",
    "            print(f\"Getting data from {Path(file).stem}\")\n",
    "            try:\n",
    "                all_results = hdf5.dump()\n",
    "                if i == 0:\n",
    "                    records = int(all_results[\"frame\"].max())\n",
    "                    total_records = records\n",
    "                    print(f\"{records} frames in {Path(file).stem}\")\n",
    "                elif i != 0:\n",
    "                    new_records = int(all_results[\"frame\"].max())\n",
    "                    total_records = total_records + new_records + 1\n",
    "                    all_results[\"frame\"] += total_records - new_records\n",
    "                    print(\n",
    "                        f\"{new_records} frames in {Path(file).stem}. {total_records} total records\")\n",
    "                all_data.append(all_results)\n",
    "            except ValueError as e:\n",
    "                if \"No objects to concatenate\" in str(e):\n",
    "                    print(f\"Skipping empty file: {Path(file).stem}\")\n",
    "                    continue\n",
    "                else:\n",
    "                    raise e\n",
    "            i += 1\n",
    "\n",
    "    all_data = pd.concat(all_data)\n",
    "    all_records = int(len(all_data[\"frame\"]))\n",
    "    print(f\"{all_records} rows in merged data frame.\")\n",
    "\n",
    "    if \"particle\" in all_data.columns:\n",
    "        all_data = all_data.drop(columns=[\"particle\"])\n",
    "\n",
    "    pickle_path = Path(input, Path(input).stem + \"_tracks.pkl.gz\")\n",
    "    with gzip.open(pickle_path, \"wb\") as f:\n",
    "        print(\"Writing pickle file.\")\n",
    "        pickle.dump(all_data, f)\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tracks(df, input):\n",
    "\n",
    "    if \"miracidia\" in input:\n",
    "        search_range = 45\n",
    "        memory = 25\n",
    "        adaptive_stop = 30\n",
    "    elif \"mosquito\" in input:\n",
    "        search_range = 750\n",
    "        memory = 100\n",
    "        adaptive_stop = None\n",
    "    elif \"planaria\" in input:\n",
    "        search_range = 750\n",
    "        memory = 100\n",
    "        adaptive_stop = None\n",
    "\n",
    "    print(\"Linking particles.\")\n",
    "    t = tp.link(df, search_range=search_range,\n",
    "                memory=memory, adaptive_stop=adaptive_stop)\n",
    "    pickle_path = Path(input, Path(input).stem + \"_tracks.pkl.gz\")\n",
    "    with gzip.open(pickle_path, \"wb\") as f:\n",
    "        print(\"Writing pickle file.\")\n",
    "        pickle.dump(t, f)\n",
    "    print(\"Filtering stubs.\")\n",
    "    t1 = tp.filter_stubs(t, 200)\n",
    "\n",
    "    return t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tracks(tracks, input):\n",
    "\n",
    "    print(\"Plotting trajectories.\")\n",
    "    save_path = Path(input, Path(input).stem + \".pdf\")\n",
    "    fig = plt.figure()\n",
    "    ax = plt.gca()\n",
    "    tp.plot_traj(tracks, ax=ax)\n",
    "    fig.savefig(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20250106a01ard_20250106_111656'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str = \"20250106a01ard_20250106_111656.24568709\"\n",
    "result = str.rsplit('.', 1)[0]\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
